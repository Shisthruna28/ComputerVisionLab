{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN on CIFAR10 ###\n",
    "1.Iswariya Manivannan<br>\n",
    "2.Sathiya Ramesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as utils_data\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda0 = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(cuda0)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = dsets.CIFAR10('/opt/datasets/cifar10', train=True, download=True, transform=transform)\n",
    "testset = dsets.CIFAR10('/opt/datasets/cifar10', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(40)\n",
    "torch.cuda.manual_seed(40)\n",
    "np.random.seed(2)\n",
    "trainloader = utils_data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers=2)\n",
    "testloader = utils_data.DataLoader(testset, batch_size = BATCH_SIZE, shuffle = True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, ng, nz, nc):\n",
    "        \n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self._layer = nn.Sequential(nn.ConvTranspose2d(nz, ng*8, 4, 1, 0, bias = False),\n",
    "                                   nn.BatchNorm2d(ng*8),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.ConvTranspose2d(ng*8, ng*4, 4, 2, 1, bias = False),\n",
    "                                   nn.BatchNorm2d(ng*4),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.ConvTranspose2d(ng*4, ng*2, 4, 2, 1, bias = False),\n",
    "                                   nn.BatchNorm2d(ng*2),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.ConvTranspose2d(ng*2, ng, 4, 2, 1, bias = False),\n",
    "                                   nn.BatchNorm2d(ng),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.ConvTranspose2d(ng, nc, 4, 1, 1, bias = False),\n",
    "                                   nn.BatchNorm2d(nc),\n",
    "                                   nn.Tanh())\n",
    "     \n",
    "    # Weight initialization\n",
    "    def weight_init(self):\n",
    "\n",
    "        for m in self._layer:\n",
    "            \n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                \n",
    "                m.weight.detach().normal_(0.0, 0.02)\n",
    "            \n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                \n",
    "                m.weight.detach().normal_(1.0, 0.02)\n",
    "                m.bias.detach().zero_()\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self._layer(x)\n",
    "\n",
    "        return x\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, nd, nc):\n",
    "        \n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self._layer = nn.Sequential(nn.Conv2d(nc, nd, 4, 2, 1, bias=False),\n",
    "                                   nn.LeakyReLU(0.2, True),\n",
    "                                   nn.Conv2d(nd, nd*2, 4, 2, 1, bias=False),\n",
    "                                   nn.BatchNorm2d(nd*2),\n",
    "                                   nn.LeakyReLU(0.2, True),\n",
    "                                   nn.Conv2d(nd*2, nd*4, 4, 2, 1, bias=False),\n",
    "                                   nn.BatchNorm2d(nd*4),\n",
    "                                   nn.LeakyReLU(0.2, True),\n",
    "                                   nn.Conv2d(nd*4, nd*8, 4, 2, 1, bias=False),\n",
    "                                   nn.BatchNorm2d(nd*8),\n",
    "                                   nn.LeakyReLU(0.2, True),\n",
    "                                   nn.Conv2d(nd*8, 1, 4, 2, 1, bias=False),\n",
    "                                   nn.Sigmoid())\n",
    "        \n",
    "    \n",
    "    # Weight initialization\n",
    "    def weight_init(self):\n",
    "\n",
    "        for m in self._layer:\n",
    "            \n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                \n",
    "                m.weight.detach().normal_(0.0, 0.02)\n",
    "            \n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                \n",
    "                m.weight.detach().normal_(1.0, 0.02)\n",
    "                m.bias.detach().zero_()\n",
    "                \n",
    "                \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self._layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng, nd = 64, 64\n",
    "nc = 3\n",
    "nz = 100\n",
    "\n",
    "net_G = Generator(64, 100, 3).to(cuda0)\n",
    "net_D = Discriminator(64, 3).to(cuda0)\n",
    "\n",
    "net_D.weight_init()\n",
    "net_G.weight_init()\n",
    "\n",
    "\n",
    "torch.manual_seed(40)\n",
    "torch.cuda.manual_seed(40)\n",
    "np.random.seed(2)\n",
    "\n",
    "fixed_noise = torch.randn((BATCH_SIZE, nz, 1, 1), device = cuda0)\n",
    "\n",
    "criterion = nn.BCELoss().to(cuda0)\n",
    "\n",
    "optimizer_G = optim.Adam(net_G.parameters(), lr = 0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(net_D.parameters(), lr = 0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imaniv2s/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0  Generator loss:3.6356730461120605  Discriminator loss:0.7365531325340271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imaniv2s/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1, 1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1  Generator loss:2.617655038833618  Discriminator loss:0.8733205795288086\n",
      "Epoch:2  Generator loss:2.3234357833862305  Discriminator loss:0.8913309574127197\n",
      "Epoch:3  Generator loss:1.7966266870498657  Discriminator loss:1.0222936868667603\n",
      "Epoch:4  Generator loss:1.6936454772949219  Discriminator loss:1.034201741218567\n",
      "Epoch:5  Generator loss:1.6871528625488281  Discriminator loss:1.0132089853286743\n",
      "Epoch:6  Generator loss:1.7919436693191528  Discriminator loss:0.9402526021003723\n",
      "Epoch:7  Generator loss:1.775393009185791  Discriminator loss:0.9213801026344299\n",
      "Epoch:8  Generator loss:1.7375982999801636  Discriminator loss:0.9218801259994507\n",
      "Epoch:9  Generator loss:1.7774029970169067  Discriminator loss:0.8927140831947327\n",
      "Epoch:10  Generator loss:1.8237316608428955  Discriminator loss:0.8603561520576477\n",
      "Epoch:11  Generator loss:1.883961796760559  Discriminator loss:0.8127108216285706\n",
      "Epoch:12  Generator loss:1.979876160621643  Discriminator loss:0.7742466926574707\n",
      "Epoch:13  Generator loss:2.018179416656494  Discriminator loss:0.7737868428230286\n",
      "Epoch:14  Generator loss:2.0701584815979004  Discriminator loss:0.7250838279724121\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    \n",
    "    running_loss_G = 0\n",
    "    running_loss_D = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        \n",
    "        Images = images.to(cuda0)\n",
    "        Labels = labels.to(cuda0)\n",
    "        \n",
    "        ones = torch.ones(Images.size(0), device = cuda0)\n",
    "        zeros = torch.zeros(Images.size(0), device = cuda0)\n",
    "        \n",
    "        # Training Discriminator\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        D_real = net_D(Images)\n",
    "        real_loss = criterion(D_real, ones)\n",
    "        \n",
    "        real_loss.backward()\n",
    "        \n",
    "        noise = torch.randn((Images.size(0), nz, 1, 1), device = cuda0)\n",
    "        \n",
    "        G_image = net_G(noise)\n",
    "        \n",
    "        D_fake = net_D(G_image)\n",
    "        fake_loss = criterion(D_fake, zeros)\n",
    "        \n",
    "        fake_loss.backward()\n",
    "        \n",
    "        total_loss = real_loss + fake_loss\n",
    "        \n",
    "        running_loss_D += total_loss\n",
    "        \n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # Training Generator\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        noise = torch.randn((Images.size(0), nz, 1, 1), device = cuda0)\n",
    "        \n",
    "        G_fake_image = net_G(noise)\n",
    "        \n",
    "        D_output = net_D(G_fake_image)\n",
    "        \n",
    "        G_loss = criterion(D_output, ones)\n",
    "        \n",
    "        running_loss_G += G_loss\n",
    "        \n",
    "        G_loss.backward()\n",
    "        \n",
    "        optimizer_G.step()\n",
    "    \n",
    "    # Visualizing images for every 200 batches\n",
    "        if i % 200 == 0:\n",
    "            \n",
    "            vutils.save_image(images, 'saved_images/real_img.png')\n",
    "            fake_img = net_G(fixed_noise)\n",
    "            vutils.save_image(fake_img, 'saved_images/fake_img_%3d.png'%(epoch))\n",
    "            \n",
    "        \n",
    "    \n",
    "    print(f\"Epoch:{epoch}  Generator loss:{running_loss_G/len(trainloader)}  Discriminator loss:{running_loss_D/len(trainloader)}\")\n",
    "    \n",
    "    # Saving the model\n",
    "    \n",
    "    torch.save(net_G.state_dict(), 'model/net_G_model_%d.th' %(epoch)) \n",
    "    torch.save(net_D.state_dict(), 'model/net_D_model_%d.th'%(epoch))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
