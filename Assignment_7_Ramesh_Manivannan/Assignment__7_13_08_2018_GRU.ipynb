{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMdIPTQb5ISS"
   },
   "source": [
    "### MNIST classification  using  custom GRU layer\n",
    "1.Iswariya Manivannan<br>\n",
    "2.Sathiya Ramesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v4t-nvpb5ISY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as utils_data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "torch.manual_seed(40)\n",
    "torch.cuda.manual_seed(40)\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "EKsu0fVv5ISp",
    "outputId": "84b50ea0-58f2-4249-9632-692142297ec7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda0 = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(cuda0)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "ZqYdqTCi5IS_",
    "outputId": "4f30f708-f3df-4dd9-eba8-f46521df306e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = dsets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset =  dsets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bu3ReYZM5ITm"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sZHK-Eh5IT1"
   },
   "outputs": [],
   "source": [
    "train_set_size = int(0.8 * len(trainset))    # Train set - Val set split is 80% - 20%\n",
    "train_indices = np.random.choice(np.arange(len(trainset)), train_set_size, replace = False)  # Getting the random 80% of train data from train set\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "\n",
    "# Getting the 20% val data not present in train indices\n",
    "val_indices = np.setdiff1d(np.arange(len(trainset)), train_indices, assume_unique= True)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "trainloader = utils_data.DataLoader(trainset, batch_size = BATCH_SIZE, sampler=train_sampler, num_workers=2)\n",
    "valloader = utils_data.DataLoader(trainset, batch_size = BATCH_SIZE, sampler=val_sampler, num_workers=2)\n",
    "testloader = utils_data.DataLoader(testset, batch_size = BATCH_SIZE, shuffle = True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZkmgenYg5IUB"
   },
   "source": [
    "Custom GRU Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BmZ3OnGa5IUG"
   },
   "outputs": [],
   "source": [
    "class gru(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=False, dropout=0):\n",
    "        \n",
    "        super(gru, self).__init__()\n",
    "        self.batch_first = batch_first\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_layer = nn.Dropout(dropout, inplace=True)\n",
    "        self.input2hidden_layer = nn.ModuleList()\n",
    "        self.statei_layer=nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            input_size = input_size if i == 0 else hidden_size\n",
    "            self.input2hidden_layer.append(nn.Linear(input_size, hidden_size * 2))\n",
    "            self.statei_layer.append(nn.Linear(input_size, hidden_size))\n",
    "            \n",
    "        self.hidden2hidden_layer = nn.ModuleList([nn.Linear(hidden_size, hidden_size * 2) for i in range(num_layers)])\n",
    "        self.stateh_layer = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for i in range(num_layers)])\n",
    "    \n",
    "    # forward for a single input\n",
    "    def forward_step(self, input, hidden):\n",
    "        \n",
    "        nowh = hidden\n",
    "        nxth_list, nxtc_list = [], []\n",
    "        \n",
    "        for L in range(self.num_layers):\n",
    "            if L > 0: input = self.dropout_layer(nxth_list[L - 1])  \n",
    "            h= nowh[L]  \n",
    "            gate_vector = self.input2hidden_layer[L](input)+self.hidden2hidden_layer[L](h)\n",
    "            updategate, resetgate = gate_vector.chunk(2, 1)\n",
    "            updategate = F.sigmoid(updategate)\n",
    "            resetgate = F.sigmoid(resetgate)\n",
    "            state=self.statei_layer[L](input)+self.stateh_layer[L](h*resetgate)\n",
    "            state = F.tanh(state)  \n",
    "            hy = (1-updategate)*h+updategate*state\n",
    "            nxth_list.append(hy)\n",
    "            \n",
    "        nxth = torch.cat(nxth_list, 0).view(self.num_layers, input.size(0),self.hidden_size)\n",
    "        output = nxth_list[-1]  \n",
    "        return output, nxth\n",
    "     \n",
    "    # forward for sequnce input      \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        if self.batch_first: \n",
    "            input=input.transpose(0, 1)\n",
    "        output = []\n",
    "        \n",
    "        for _in in input:\n",
    "            _out, hidden = self.forward_step(_in, hidden)\n",
    "            output.append(_out)\n",
    "        output=torch.cat(output, 0).view(input.size(0), *output[0].size())\n",
    "        \n",
    "        if self.batch_first: \n",
    "            output = output.transpose(0, 1)\n",
    "            \n",
    "        return output, hidden\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a350C5Jd5IUR"
   },
   "source": [
    "GRU Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lcFiVRgZ5IUZ"
   },
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        \n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.gru = gru(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "     \n",
    "    def forward(self, x):\n",
    "        \n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(cuda0)    \n",
    "        out, hn = self.gru(x, h0)      \n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9xWQLfs5IUs"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, **kwargs):\n",
    "    \n",
    "    if kwargs['phase'] == 'Training':\n",
    "        model.train()        \n",
    "    if kwargs['phase'] == 'Validation':\n",
    "        model.eval() \n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss().to(cuda0)    \n",
    "    running_loss = 0\n",
    "    running_pred = 0    \n",
    "    batch_wise_loss = [] \n",
    "    \n",
    "    for i, (images, labels) in enumerate(kwargs['dataloader']):  \n",
    "        \n",
    "        Images = images.view(-1, seq_dim, input_dim).to(cuda0)\n",
    "        Labels = labels.to(cuda0)        \n",
    "        y_pred = model(Images)\n",
    "        loss = criterion(y_pred, Labels)\n",
    "        running_loss += loss.item()\n",
    "        batch_wise_loss.append(loss.item())                 \n",
    "        if kwargs['phase'] == 'Training':\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            \n",
    "        # Finding the number of correct predictions in the training set\n",
    "        _, pred_class = torch.max(y_pred.data, 1)\n",
    "        running_pred += (pred_class.cpu() == Labels.data.cpu()).sum()\n",
    "        \n",
    "    acc = 100. * (running_pred.numpy()/len(kwargs['dataloader'].sampler))\n",
    "    return running_loss/len(kwargs['dataloader']), acc, batch_wise_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1208
    },
    "colab_type": "code",
    "id": "u5ONwJ-W5IU4",
    "outputId": "78b8f874-e8ba-4648-a256-868b25d79dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Train Loss: 1.46462  Train Acc:49.37083%    Val Loss: 0.63514  Val Acc:79.40000% \n",
      "Epoch: 3  Train Loss: 0.13936  Train Acc:95.91250%    Val Loss: 0.12911  Val Acc:96.08333% \n",
      "Epoch: 6  Train Loss: 0.08180  Train Acc:97.52917%    Val Loss: 0.10002  Val Acc:97.02500% \n",
      "Epoch: 9  Train Loss: 0.05851  Train Acc:98.22292%    Val Loss: 0.07933  Val Acc:97.72500% \n",
      "Epoch: 12  Train Loss: 0.04655  Train Acc:98.53750%    Val Loss: 0.06637  Val Acc:97.99167% \n"
     ]
    }
   ],
   "source": [
    "train_loss_values = []\n",
    "train_acc_values = []\n",
    "val_loss_values = []\n",
    "val_acc_values = []\n",
    "best_acc = 0\n",
    "learning_rate = 0.1\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 10\n",
    "seq_dim = 28 \n",
    "\n",
    "model = GRUModel(input_dim, hidden_dim, layer_dim, output_dim).to(cuda0)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) \n",
    "\n",
    "for epoch in range(EPOCHS):   \n",
    "    \n",
    "    train_loss, train_acc, _ = train(model, optimizer, dataloader = trainloader,  phase = 'Training')  \n",
    "    train_loss_values.append(train_loss)\n",
    "    train_acc_values.append(train_acc)\n",
    "\n",
    "    val_loss, val_acc, _ = train(model, optimizer, dataloader = valloader,  phase = 'Validation') \n",
    "    val_loss_values.append(val_loss)\n",
    "    val_acc_values.append(val_acc)\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        classifier_model_checkpoint = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "    if epoch % 3 == 0:\n",
    "        print(f'Epoch: {epoch}  Train Loss: {train_loss:.5f}  Train Acc:{train_acc:.5f}%\\\n",
    "    Val Loss: {val_loss:.5f}  Val Acc:{val_acc:.5f}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFUbQ-Qp5IVP"
   },
   "outputs": [],
   "source": [
    "def predict(model, testloader):\n",
    "    \n",
    "    model.eval()\n",
    "    pred_val = 0\n",
    "    prediction_array = np.array([])\n",
    "    labels_array = np.array([]) \n",
    "    \n",
    "    for images, labels in testloader:  \n",
    "        \n",
    "        Images = images.view(-1, seq_dim, input_dim).to(cuda0)\n",
    "        Labels = labels.to(cuda0)\n",
    "        pred = model(Images)        \n",
    "        \n",
    "        # Finding the number of correct predictions in the training set\n",
    "        _, pred_label = torch.max(pred.data, 1)\n",
    "        pred_val += (pred_label.cpu() == Labels.data.cpu()).sum()     \n",
    "        \n",
    "        # Storing predictions and true labels in numpy arrays for printing confusion matrix\n",
    "        prediction_array = np.append(prediction_array, pred_label.cpu().numpy(), axis =0)\n",
    "        labels_array = np.append(labels_array, Labels.data.cpu().numpy(), axis = 0)\n",
    "        \n",
    "    Test_acc = 100. * (pred_val.numpy()/len(testloader.dataset))\n",
    "    return Test_acc, prediction_array, labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zM9Br-YB5IVd"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(classifier_model_checkpoint)\n",
    "torch.save(model.state_dict(), \"GRU_model.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nTk8c7QL5IVv",
    "outputId": "577054de-f494-4261-85a0-a8f9beb7cdc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:98.24000% \n"
     ]
    }
   ],
   "source": [
    "Test_acc, Predicted_labels, True_labels = predict(model, testloader) # Test set accuracy\n",
    "\n",
    "print(f'Test Accuracy:{Test_acc:.5f}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSJHwpfhHLxA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": " Assignment _7_13_08_2018.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
