{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMdIPTQb5ISS"
   },
   "source": [
    "### MNIST classification  using  custom LSTM layer\n",
    "1.Iswariya Manivannan<br>\n",
    "2.Sathiya Ramesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v4t-nvpb5ISY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as utils_data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "torch.manual_seed(40)\n",
    "torch.cuda.manual_seed(40)\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "EKsu0fVv5ISp",
    "outputId": "00e6d2bc-71f3-414e-a1ae-b5b12b504ed4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda0 = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(cuda0)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "ZqYdqTCi5IS_",
    "outputId": "a8bf9cc0-12a8-4ea7-9e60-74aa964bef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = dsets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset =  dsets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bu3ReYZM5ITm"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sZHK-Eh5IT1"
   },
   "outputs": [],
   "source": [
    "train_set_size = int(0.8 * len(trainset))    # Train set - Val set split is 80% - 20%\n",
    "train_indices = np.random.choice(np.arange(len(trainset)), train_set_size, replace = False)  # Getting the random 80% of train data from train set\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "\n",
    "# Getting the 20% val data not present in train indices\n",
    "val_indices = np.setdiff1d(np.arange(len(trainset)), train_indices, assume_unique= True)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "#print(np.any(np.isin(train_indices, val_indices)))\n",
    "\n",
    "trainloader = utils_data.DataLoader(trainset, batch_size = BATCH_SIZE, sampler=train_sampler, num_workers=2)\n",
    "valloader = utils_data.DataLoader(trainset, batch_size = BATCH_SIZE, sampler=val_sampler, num_workers=2)\n",
    "testloader = utils_data.DataLoader(testset, batch_size = BATCH_SIZE, shuffle = True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZkmgenYg5IUB"
   },
   "source": [
    "### Custom LSTM module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BmZ3OnGa5IUG"
   },
   "outputs": [],
   "source": [
    "class lstm(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_first=False, dropout=0):\n",
    "        \n",
    "        super(lstm, self).__init__()\n",
    "        self.batch_first = batch_first\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_layer = nn.Dropout(dropout, inplace=True)\n",
    "        self.input2hidden_layer = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            input_size = input_size if i == 0 else hidden_size\n",
    "            self.input2hidden_layer.append(nn.Linear(input_size, hidden_size * 4)) \n",
    "        self.hidden2hidden_layer = nn.ModuleList([nn.Linear(hidden_size, hidden_size * 4) for i in range(num_layers)])\n",
    "    \n",
    "    # forward for a single input\n",
    "    def forward_step(self, input, hidden):\n",
    "        nowh, nowc = hidden\n",
    "        nxth_list, nxtc_list = [], []\n",
    "        \n",
    "        for L in range(self.num_layers):\n",
    "            if L > 0: input = self.dropout_layer(nxth_list[L - 1])  \n",
    "            h, c = nowh[L], nowc[L]  \n",
    "            gate_vector = self.input2hidden_layer[L](input)+self.hidden2hidden_layer[L](h)\n",
    "            ingate, forgetgate, cellgate, outgate = gate_vector.chunk(4, 1)\n",
    "            ingate = F.sigmoid(ingate)\n",
    "            forgetgate = F.sigmoid(forgetgate)\n",
    "            cellgate = F.tanh(cellgate)  \n",
    "            outgate = F.sigmoid(outgate)\n",
    "            cy = (forgetgate * c) + (ingate * cellgate)\n",
    "            hy = outgate * F.tanh(cy)   \n",
    "            nxth_list.append(hy)\n",
    "            nxtc_list.append(cy)\n",
    "            \n",
    "        nxth = torch.cat(nxth_list, 0).view(self.num_layers, input.size(0),self.hidden_size)\n",
    "        nxtc = torch.cat(nxtc_list, 0).view(self.num_layers, input.size(0),self.hidden_size)\n",
    "        output = nxth_list[-1]  \n",
    "        return output, (nxth, nxtc)\n",
    "     \n",
    "    # forward for sequnce input      \n",
    "    def forward(self, input, hidden):\n",
    "        if self.batch_first: \n",
    "            input=input.transpose(0, 1)\n",
    "        output = []\n",
    "        for _in in input:\n",
    "            _out, hidden = self.forward_step(_in, hidden)\n",
    "            output.append(_out)\n",
    "        output=torch.cat(output, 0).view(input.size(0), *output[0].size())\n",
    "        if self.batch_first: \n",
    "            output = output.transpose(0, 1)\n",
    "        return output, hidden\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a350C5Jd5IUR"
   },
   "source": [
    "### LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lcFiVRgZ5IUZ"
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = lstm(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "     \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(cuda0)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(cuda0)        \n",
    "        out, (hn, cn) = self.lstm(x, (h0,c0))        \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9xWQLfs5IUs"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, **kwargs):\n",
    "    \n",
    "    if kwargs['phase'] == 'Training':\n",
    "        model.train()        \n",
    "    if kwargs['phase'] == 'Validation':\n",
    "        model.eval() \n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss().to(cuda0)  \n",
    "    \n",
    "    running_loss = 0\n",
    "    running_pred = 0  \n",
    "    batch_wise_loss = [] \n",
    "    \n",
    "    for i, (images, labels) in enumerate(kwargs['dataloader']):  \n",
    "        \n",
    "        Images = images.view(-1, seq_dim, input_dim).to(cuda0)\n",
    "        Labels = labels.to(cuda0) \n",
    "        \n",
    "        y_pred = model(Images)\n",
    "        loss = criterion(y_pred, Labels)\n",
    "        running_loss += loss.item()\n",
    "        batch_wise_loss.append(loss.item()) \n",
    "        \n",
    "        if kwargs['phase'] == 'Training':\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            \n",
    "        # Finding the number of correct predictions in the training set\n",
    "        _, pred_class = torch.max(y_pred.data, 1)\n",
    "        running_pred += (pred_class.cpu() == Labels.data.cpu()).sum()\n",
    "        \n",
    "    acc = 100. * (running_pred.numpy()/len(kwargs['dataloader'].sampler))\n",
    "    return running_loss/len(kwargs['dataloader']), acc, batch_wise_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "colab_type": "code",
    "id": "u5ONwJ-W5IU4",
    "outputId": "d34e5e50-3744-4d20-d576-178d85a59917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Train Loss: 2.22713  Train Acc:15.87917%    Val Loss: 1.93298  Val Acc:25.74167% \n",
      "Epoch: 3  Train Loss: 0.20006  Train Acc:93.90625%    Val Loss: 0.20843  Val Acc:93.30000% \n",
      "Epoch: 6  Train Loss: 0.08703  Train Acc:97.37917%    Val Loss: 0.08682  Val Acc:97.45833% \n",
      "Epoch: 9  Train Loss: 0.05681  Train Acc:98.26667%    Val Loss: 0.07347  Val Acc:97.83333% \n",
      "Epoch: 12  Train Loss: 0.03804  Train Acc:98.80833%    Val Loss: 0.06646  Val Acc:98.16667% \n"
     ]
    }
   ],
   "source": [
    "train_loss_values = []\n",
    "train_acc_values = []\n",
    "val_loss_values = []\n",
    "val_acc_values = []\n",
    "best_acc = 0\n",
    "learning_rate = 0.1\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 3\n",
    "output_dim = 10\n",
    "seq_dim = 28 \n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim).to(cuda0)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) \n",
    "\n",
    "for epoch in range(EPOCHS):  \n",
    "    \n",
    "    train_loss, train_acc, _ = train(model, optimizer, dataloader = trainloader,  phase = 'Training')  \n",
    "    train_loss_values.append(train_loss)\n",
    "    train_acc_values.append(train_acc)\n",
    "\n",
    "    val_loss, val_acc, _ = train(model, optimizer, dataloader = valloader,  phase = 'Validation') \n",
    "    val_loss_values.append(val_loss)\n",
    "    val_acc_values.append(val_acc)\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        classifier_model_checkpoint = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "    if epoch % 3 == 0:\n",
    "        print(f'Epoch: {epoch}  Train Loss: {train_loss:.5f}  Train Acc:{train_acc:.5f}%\\\n",
    "    Val Loss: {val_loss:.5f}  Val Acc:{val_acc:.5f}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFUbQ-Qp5IVP"
   },
   "outputs": [],
   "source": [
    "def predict(model, testloader):\n",
    "    \n",
    "    model.eval()\n",
    "    pred_val = 0\n",
    "    prediction_array = np.array([])\n",
    "    labels_array = np.array([])  \n",
    "    \n",
    "    for images, labels in testloader:\n",
    "        \n",
    "        Images = images.view(-1, seq_dim, input_dim).to(cuda0)\n",
    "        Labels = labels.to(cuda0)\n",
    "        pred = model(Images)     \n",
    "        \n",
    "        # Finding the number of correct predictions in the training set\n",
    "        _, pred_label = torch.max(pred.data, 1)\n",
    "        pred_val += (pred_label.cpu() == Labels.data.cpu()).sum() \n",
    "        \n",
    "        # Storing predictions and true labels in numpy arrays for printing confusion matrix\n",
    "        prediction_array = np.append(prediction_array, pred_label.cpu().numpy(), axis =0)\n",
    "        labels_array = np.append(labels_array, Labels.data.cpu().numpy(), axis = 0)\n",
    "        \n",
    "    Test_acc = 100. * (pred_val.numpy()/len(testloader.dataset))\n",
    "    return Test_acc, prediction_array, labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zM9Br-YB5IVd"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(classifier_model_checkpoint)\n",
    "torch.save(model.state_dict(), \"LSTM_model.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nTk8c7QL5IVv",
    "outputId": "577054de-f494-4261-85a0-a8f9beb7cdc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:98.34000% \n"
     ]
    }
   ],
   "source": [
    "Test_acc, Predicted_labels, True_labels = predict(model, testloader) # Test set accuracy\n",
    "\n",
    "print(f'Test Accuracy:{Test_acc:.5f}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSJHwpfhHLxA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Assignment _7_13_08_2018.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
